---
version: 1.0
lm_model:
  bert_models: # bert model(s) definition, one bert model for each node type having text data
    -
      node_type: node
      model_name: "allenai/scibert_scivocab_uncased"
      gradient_checkpoint: true
gsf:
  basic:
    model_encoder_type: lm
    graph_name: ogbn-arxiv
    backend: nccl
    num_gpus: 8
    ip_config: ip_configp4euwest12p.txt
    part_config: ./ogbn-arxiv-graph-512-scibert-nc-2p/ogbn-arxiv.json
    verbose: true
    use_bert_cache: false
    refresh_cache: false
    gnn_warmup_epochs: 0
    mixed_precision: false
    no_validation: true
    mp_opt_level: O2
    train_nodes: -1
    debug: false
  gnn:
    fanout: "4"
    n_layers: 1
    n_hidden: 128
    mini_batch_infer: true
  rgcn:
    n_bases: -1
    use_self_loop: true
    use_dot_product: true
    self_loop_init: false
    sparse_lr: 1e-2
    use_node_embeddings: false
  input:
    restore_model_path: null
  output:
    save_model_path: ./models/ogb_arxiv/train_val/ogb_arxiv_hf_train_val_1p_2t_model
    save_embeds_path: null
    save_model_per_iters: 1000
    mlflow_exp_name: "m5_gnn_exp"
    mlflow_run_name: "m5_gnn_run"
    mlflow_report_frequency: 50
  hyperparam:
    dropout: 0.
    lr: 0.001
    bert_tune_lr: 0.0001
    n_epochs: 320
    batch_size: 128
    eval_batch_size: 1024
    bert_infer_bs: 64
    wd_l2norm: 0
  node_classification:
    predict_ntype: "node"
    label_field: "labels"
    multilabel: false
    num_classes: 40
