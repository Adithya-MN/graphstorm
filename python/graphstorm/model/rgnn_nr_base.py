"""Node regression based on RGNN
"""

import time
import torch as th

import torch.nn as nn
from torch.nn.parallel import DistributedDataParallel
import dgl

import inspect
from .rgnn_node_base import M5GNNNodeModel

class Regression(nn.Module):
    def __init__(self,
                 h_dim,
                 dropout=0):
        super(Regression, self).__init__()
        self.h_dim = h_dim
        self.decoder = nn.Parameter(th.Tensor(h_dim, 1))
        nn.init.xavier_uniform_(self.decoder)
        self.dropout = nn.Dropout(dropout)

    def forward(self, h):
        return th.matmul(h, self.decoder)

class M5GNNNodeRegressModel(M5GNNNodeModel):
    """ RGNN node regression model

    Parameters
    ----------
    g: DGLGraph
        The graph used in training and testing
    config: M5GNNConfig
        The M5 GNN configuration
    bert_model: dict
        A dict of BERT models in a format of ntype -> bert_model
    train_task: bool
        Whether it is a training task
    """
    def __init__(self, g, config, bert_model, train_task=True):
        super(M5GNNNodeRegressModel, self).__init__(g, config, bert_model, train_task)

        self.model_conf = {
            'task': 'node_regression',
            'predict_ntype': self.predict_ntype,
            # GNN
            'gnn_model': self.gnn_model_type,
            'num_layers': self.n_layers,
            'hidden_size': self.n_hidden,
            'num_bases': self.n_bases,
            'dropout': self.dropout,
            'use_self_loop': self.use_self_loop,
        }
        # logging all the params of this experiment
        self.log_params(self.__dict__)
        self.log_params(config.__dict__)

    def init_dist_decoder(self, train):
        dev_id = self.dev_id
        if self.pretrain_emb_layer:
            in_units = self.n_hidden
        else:
            # if the embedding layer is not set the dimension here will be the same as the bert hidden size
            in_units = self.bert_hidden_size[self.predict_ntype]
        decoder = Regression(in_units)
        decoder = decoder.to(dev_id)
        self.decoder = DistributedDataParallel(decoder, device_ids=[dev_id], output_device=dev_id, find_unused_parameters=True)


    def init_m5gnn_model(self, train=True):
        ''' Initialize the M5GNN model.

        Argument
        --------
        train : bool
            Indicate whether the model is initialized for training.
        '''
        super(M5GNNNodeRegressModel, self).init_m5gnn_model(train)
        mse_loss_func = nn.MSELoss()
        mse_loss_func = mse_loss_func.to(self.dev_id)
        def loss_func(logits, lbl):
            # Make sure the lable is a float tensor
            lbl = lbl.float()
            return mse_loss_func(logits, lbl)
        self.loss_func = loss_func

    def predict(self, logits):
        '''Make prediction on the input logits.

        Parameters
        ----------
        logits : tensor
            The logits generated by the model.

        Returns
        -------
        tensor
            The predicted results.
        '''
        return logits
